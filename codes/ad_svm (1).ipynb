{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFB0ljLPVezD"
      },
      "outputs": [],
      "source": [
        "#Farklı metodla SVM:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETIlxqf541j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1FmTHZJZPNK",
        "outputId": "fcb9e9d2-729d-4297-871f-8cf398d00302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doğruluk (Accuracy): 0.6388\n",
            "Hassasiyet (Precision Macro): 0.5876\n",
            "Hassasiyet (Precision Micro): 0.6388\n",
            "Geri Çağırma (Recall Macro): 0.5787\n",
            "Geri Çağırma (Recall Micro): 0.6388\n",
            "F1 Skoru (Macro): 0.5804\n",
            "F1 Skoru (Micro): 0.6388\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Excel dosyasından verileri oku\n",
        "df = pd.read_excel(\"/content/covidsonrasi.xlsx\")\n",
        "\n",
        "# NaN değerlere sahip satırları sil\n",
        "df = df.dropna()\n",
        "\n",
        "sentences = df[\"tweets\"].values  # Cümleler\n",
        "labels = df[\"total\"].values  # Sınıf etiketleri\n",
        "\n",
        "# Özellik çıkarma: cümleleri kelime sayısına göre özellik olarak temsil et\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['tweets'].values.astype(str))\n",
        "\n",
        "# Özellikleri standartlaştır\n",
        "scaler = StandardScaler(with_mean=False, with_std=False)\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Veri kümesini eğitim ve test kümelerine ayır\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.3, random_state=1)\n",
        "\n",
        "# SVM modelini eğit\n",
        "svm_clf = LinearSVC(C=1, loss=\"hinge\")\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Test kümesini kullanarak modeli değerlendir\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "# Doğruluk (Accuracy) hesapla\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Hassasiyet (Precision) hesapla (Makro ve Mikro)\n",
        "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
        "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
        "\n",
        "# Geri çağırma (Recall) hesapla (Makro ve Mikro)\n",
        "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
        "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
        "\n",
        "# F1 skoru hesapla (Makro ve Mikro)\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(\"Doğruluk (Accuracy): {:.4f}\".format(accuracy))\n",
        "print(\"Hassasiyet (Precision Macro): {:.4f}\".format(precision_macro))\n",
        "print(\"Hassasiyet (Precision Micro): {:.4f}\".format(precision_micro))\n",
        "print(\"Geri Çağırma (Recall Macro): {:.4f}\".format(recall_macro))\n",
        "print(\"Geri Çağırma (Recall Micro): {:.4f}\".format(recall_micro))\n",
        "print(\"F1 Skoru (Macro): {:.4f}\".format(f1_macro))\n",
        "print(\"F1 Skoru (Micro): {:.4f}\".format(f1_micro))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEPNq0rhZWKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8eeca3a-0b89-4d59-8ebb-9956ff5d7e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class      Precision  Recall     F1-Score   Support   \n",
            "0          69.79%     75.71%     72.63%     1684      \n",
            "1          45.54%     38.26%     41.58%     894       \n",
            "macro avg  57.66%     56.98%     57.10%     2578      \n",
            "weighted avg 61.38%     62.72%     61.86%     2578      \n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Print the modified report\n",
        "print(\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"))\n",
        "for label, metrics in report.items():\n",
        "    if label != \"accuracy\":\n",
        "        precision = metrics.get('precision', {})\n",
        "        recall = metrics.get('recall', {})\n",
        "        f1_score = metrics.get('f1-score', {})\n",
        "        support = metrics.get('support', {})\n",
        "\n",
        "        precision_str = \"{:.2f}%\".format(precision * 100) if isinstance(precision, float) else \"N/A\"\n",
        "        recall_str = \"{:.2f}%\".format(recall * 100) if isinstance(recall, float) else \"N/A\"\n",
        "        f1_score_str = \"{:.2f}%\".format(f1_score * 100) if isinstance(f1_score, float) else \"N/A\"\n",
        "        support_str = str(support) if isinstance(support, int) else \"N/A\"\n",
        "\n",
        "        print(\"{:<10} {:<10} {:<10} {:<10} {:<10}\".format(label, precision_str, recall_str, f1_score_str, support_str))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "oBvFKaJOYO1W",
        "outputId": "31d9752b-c29b-477e-8c87-201a3e5bf5df"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-36f97516f146>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_bin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# df, vectorizer, scaler gibi değişkenlerin ve X_train, X_test, y_train, y_test'in tanımlandığı bir yer olduğunu varsayalım\n",
        "\n",
        "# Binarize the labels\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_clf = MultinomialNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the class probabilities\n",
        "y_pred_prob = nb_clf.predict_proba(X_test)\n",
        "\n",
        "# Calculate the false positive rate, true positive rate, and AUC for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "num_classes = 3  # Sınıf sayısı\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot the ROC curves for each class\n",
        "plt.figure()\n",
        "colors = ['blue', 'red', 'green']\n",
        "for i, color in zip(range(num_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='Class {} (AUC = {:.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - OvA')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Determine the number of classes\n",
        "num_classes = len(np.unique(y_test))\n",
        "\n",
        "# Calculate the ROC AUC score for each class\n",
        "roc_area = []\n",
        "for i in range(num_classes):\n",
        "    roc_area.append(round(roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i]), 2))\n",
        "\n",
        "print(\"Approximate ROC Area for each class:\", roc_area)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Xdx2_kgwMGWD",
        "outputId": "69a65ab8-1663-4926-bba2-a89301519d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8fb9bc54c9fe>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mroc_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mroc_area\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_bin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Approximate ROC Area for each class:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "equsug-6YO1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26feafaa-1355-444c-9c01-06196c24e606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.66\n",
            "Recall: 0.64\n",
            "F-measure: 0.64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# y_test ve y_pred gibi değişkenlerin tanımlandığı bir yer olduğunu varsayalım\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "# Calculate precision, recall, and F-measure\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f_measure = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F-measure: {:.2f}\".format(f_measure))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtkSVyewYO1a",
        "outputId": "c5080023-ce7d-46a8-9cd8-3144de0e7c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.50\n"
          ]
        }
      ],
      "source": [
        "# Calculate RMSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: {:.2f}\".format(rmse))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# y_pred ve y_test'in tanımlandığı bir yer olduğunu varsayalım\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "print(\"Recall: {:.2f}\".format(recall))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn7oP_WIZeDj",
        "outputId": "40ff0989-ad18-4097-ba48-5e366d3bf495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# y_pred ve y_test'in tanımlandığı bir yer olduğunu varsayalım\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "print(\"Precision: {:.2f}\".format(precision))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0_0_26CZlG1",
        "outputId": "add032c6-74ba-4343-bef5-7ef91b1793b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.66\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "a71a9e4fb054fff428071484f7faa898cb9ecb31a518fe88e3463da9af879578"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}